{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging Lab 2: Single Pixel Scanning\n",
    "\n",
    "### EECS 16A: Designing Information Devices and Systems I, Summer 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Instructions](#instructions)\n",
    "* [Lab Policies](#policies)\n",
    "* [Overview](#overview)\n",
    "* [Task 1: Images, Vectors, and Matrices](#images)\n",
    "    * [Task 1a: Working with Images](#task2a)\n",
    "    * [Task 1b: Scanning Mask Matrix](#task2b)\n",
    "* [Task 2: Imaging Simulated Pictures](#task3)\n",
    "    * [Task 2a: Software Setup](#setup)\n",
    "* [Checkoff](#checkoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='instructions'></a>\n",
    "# <span style='color:blue'>Instructions</span>\n",
    "* Complete this lab by filling in all of the required sections, marked with `\"YOUR CODE HERE\"` or `\"YOUR COMMENTS HERE\"`.\n",
    "\n",
    "\n",
    "* When you finish, submit a checkoff request to get checked off for this lab. Make sure to keep your setup ready to demo and be prepared to answer a few questions to show your understanding of each section.\n",
    "\n",
    "\n",
    "* Labs will be graded based on completion for teams of 2-4 students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='policies'></a>\n",
    "# <span style='color:blue'>Lab Policies</span>\n",
    "* **YOU MUST ATTEND THE LAB SECTION YOU ARE ENROLLED IN. If you anticipate missing a section, please notify your GSI in advance.**\n",
    "* **You are free to stay for the full allotted time and hack around with the lab setup or code, but please keep the GSI's time in mind and do not work on unrelated assignments.**\n",
    "* **Keep food and drinks (except water) away from your devices / equipment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='overview'><span style='color:blue'>Overview</span></a>\n",
    "<center>\n",
    "<img src=\"images/system_diagram.svg\" style=\"height:256px\" />\n",
    "</center>\n",
    "This week, you will write code in your Jupyter notebook to simulate scanning an image pixel-by-pixel and display the captured image. In a physical lab, your setup would resemble the one below, in which you'd set up a projector and light sensor circuit (from Imaging 1) to behave like a single pixel camera. The physical single pixel camera process would involve the following steps:\n",
    "<ul>\n",
    "    <li> The ambient light sensor component detects the amount of light in the surrounding environment. </li>\n",
    "    <li> The analog circuit is designed to output voltages proportional to the light detected i.e. more ambient light $\\rightarrow$ lower sensor resistance $\\rightarrow$ higher output voltage. </li>\n",
    "    <li> These voltages are converted into digital brightness values. </li>\n",
    "</ul>\n",
    "\n",
    "To prevent room lighting from affecting these measurements, the projector setup is usually placed in a closed cardboard box. While the projector applies masks onto the image being scanned, the light sensor detects the brightness of the illuminated pixels.\n",
    "\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/projector_setup.png\" style=\"height:256px\" />\n",
    "</center>\n",
    "\n",
    "In this virtual version of the lab, you will do the following.\n",
    "First, you will write code to generate the mask patterns that the simulated projector code uses to scan the image. \n",
    "\n",
    "Then, you will use your generated mask matrix to \"photograph\" an image with the simulation code and output the captured pixel values. \n",
    "\n",
    "Finally, you will write code to recreate the image from these captured light sensor readings. \n",
    "\n",
    "Note: To simulate real-world measurements, the `sigma` variable defined in each \"noisy imaging\"-labeled simulation cell will introduce some variability into the image measurements captured. This `sigma` variable is included to simulate the limitations of real-life lab equipment. You will learn more about noisy imaging in the Imaging 3 lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%run scripts/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='images'></a>\n",
    "# <span style='color:blue'>Task 1: Images, Vectors, and Matrices </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2a'></a>\n",
    "## <span style=\"color:blue\">Task 1a: Working with Images</span>\n",
    "A simple grayscale image can be represented using a 2D numpy array (matrix). The values stored in this array correspond to different shades of gray, where lower numbers correspond to darker pixels and higher numbers correspond to lighter pixels.  \n",
    "\n",
    "To see how this works, create a 5x5 numpy array called **`gradient_image`** with *linearly spaced* floating point values from 0 to 1. This means that gradient_image[0, 0] = 0.0, gradient_image[2, 2] = 0.5, and gradient_image[4,4] = 1.0.\n",
    "\n",
    "<span style=\"color:red\"> **Create the gradient 5x5 array here. It should look like the following:** </span>\n",
    "<br/><br/>\n",
    "<center>\n",
    "<img src=\"images/gradient.JPG\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "*Hint: Google the functions `np.linspace` (which creates a vector of equally spaced values over a specified range) and `np.reshape`!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a 5x5 gradient image with values from 0 to 1.\n",
    "gradient_image = # YOUR CODE HERE\n",
    "\n",
    "print(gradient_image)\n",
    "plt.imshow(gradient_image, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">What color does 1.0 correspond to? What about 0?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">YOUR COMMENTS HERE</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: In lab, we will be using 0 indexing, as most programming languages index in lists starting from 0.\n",
    "\n",
    "Let's suppose the 2D image we want to \"scan\" with our single pixel camera is **`gradient_image`**. What would the same image look like if it were instead represented by a 1D column vector **`gradient_image_vector`**? \n",
    "<center>\n",
    "<img src=\"images/matrix_to_col.png\" style=\"width:500px\"/>\n",
    "</center>\n",
    "\n",
    "Let's look at the 3x3 example image above (colored for illustrative purposes). Essentially, the $0$th row is flipped on its side (rotate clockwise 90 degrees), such that its left-most element is on top and its right-most element is on the bottom. The $1$st row is also flipped on its side in the same way and appended below. These steps are repeated for each subsequent row of the original 2D image until you build a `num_pixels` $\\times 1$ **column vector**.\n",
    "\n",
    "In matrix form, each pixel value in the 3x3 image is represented as a variable $iv_{ij}$, where $i$ is the row and $j$ is the column associated with the pixel location. This same image represented as a 1D column vector (called $\\vec{i}$) is:\n",
    "\n",
    "$$\\vec{i} = \\begin{bmatrix} iv_{00} \\\\ iv_{01} \\\\ iv_{02} \\\\ iv_{10} \\\\ iv_{11} \\\\ iv_{12} \\\\ iv_{20} \\\\ iv_{21} \\\\ iv_{22} \\end{bmatrix}$$\n",
    "\n",
    "**<span style=\"color:red\">Convert the 5x5 `gradient_image` that you created above into a 25x1 column vector `gradient_image_vector` and display it. You will find the command `np.reshape` helpful. What do you notice?</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the 5x5 matrix into a 25x1 column vector\n",
    "gradient_image_vector = # YOUR CODE HERE\n",
    "\n",
    "# Display the vector\n",
    "plt.imshow(gradient_image_vector, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0, 30, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2b'></a>\n",
    "## <span style=\"color:blue\">Task 1b: Scanning Mask Matrix</span>\n",
    "\n",
    "Next, we will create a \"mask\" array (matrix) to enable our simulated projector to illuminate and scan individual pixels, one at a time. This is the magic behind our virtual single pixel camera. \n",
    "\n",
    "What matrix $H$ multiplied with **`gradient_image_vector`** will return **`gradient_image_vector`**? If **`gradient_image_vector`** is represented by the column vector variable $\\vec{i}$, the act of transforming $\\vec{i}$ by a matrix $H$ into another 1D column vector $\\vec{s}$ is represented mathematically as:\n",
    "\n",
    "$$ \\vec{s} = H \\vec{i} $$\n",
    "\n",
    "This matrix multiplication represents what happens when we scan an image with our virtual single pixel camera! In the context of a real-world imaging system, $H$ represents the scanning \"mask matrix,\" whose rows are projected one-by-one onto the image we want to scan. $\\vec{s}$ represents digitized readings from the analog circuit's light sensor. In the context of the simulation, each mask in $H$ will be reshaped to match the dimensions of the image, and subsequently overlaid one at a time, with only illuminated pixel measurements contributing to the corresponding mask measurement. Each element $sr_k$ of $\\vec{s}$ corresponds to one scan (using one row $k$ of $H$, that we refer to as $H_k$). \n",
    "\n",
    "Each 1D **row of $H$** represents a **mask**. But what is a mask? In the context of our virtual single pixel camera, a mask is a way to isolate certain locations in the image while hiding others during scanning. For a 3x4 image (where 3 = height, 4 = width to match Numpy array indexing), a mask taken from **row 0 of $H$** is represented as the $1 \\times 12$ row vector below: \n",
    "\n",
    "$$\n",
    "H_0 \n",
    "= \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "However, the mask must first be converted into its 2D form, as shown below, before it's projected over the 2D image. The mask exposes only the top-left pixel of the 2D image and hides all other pixels. Note that you can convert a 2D mask into a 1D row of $H$ by appending each of the 2D mask's rows to the right of the previous row.\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/black_hite.png\" style=\"width:400px\"/>\n",
    "</center>\n",
    " \n",
    "To expose each pixel of the 3x4 image $\\vec{i}$ individually, we would need a 12x12 $H$ that has 12 masks (rows), each with a single white \"exposed\" pixel in a unique location. This means that **row 1 of $H$** (exposing $iv_{01}$) would look like:\n",
    "\n",
    "$$\n",
    "H_1 \n",
    "= \\begin{bmatrix} 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{bmatrix}\n",
    "$$\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/black_white_shifted.jpg\" style=\"width:400px\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of masking an image, one pixel at a time, and sensing the resultant ambient light performs the matrix multiplication $\\vec{s} = H \\vec{i}$ in real life. This equation implies that each element of the sensor reading column vector $\\vec{s}$ can be determined as:\n",
    "    \n",
    "$$sr_k = H_k \\vec{i}$$\n",
    "\n",
    "Where the $k$th sensor reading is determined by the $k$th row of $H$, $H_k$. Thus, projecting the 2D representation of $H_0$ shown above onto a 3x4 image represented by the column vector $\\vec{i}$ to obtain the sensor reading $sr_0$ would be mathematically equivalent to:\n",
    "\n",
    "$$\n",
    "sr_0 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{bmatrix} \\vec{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">\n",
    "What dimensions does the mask matrix $H$ for a 5x5 image have and why? </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">YOUR COMMENTS HERE</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">\n",
    "Create the mask matrix $H$ for the 5x5 image.</span>**\n",
    "\n",
    "*Hint: Google the function `np.eye`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the mask matrix `H` for scanning a 5x5 image (be careful about the dimensions!)\n",
    "H = # YOUR CODE HERE\n",
    "\n",
    "# Display this matrix\n",
    "plt.imshow(H, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">\n",
    "Multiply the $H$ matrix with `gradient_image_vector` to get the same vector back! Remember to use `np.dot` to do matrix multiplication.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recreate gradient_image_vector by multiplying `H` and `gradient_image_vector`\n",
    "gradient_image_recreate = # YOUR CODE HERE\n",
    "\n",
    "# Display the result and compare it to `gradient_image_vector`\n",
    "plt.imshow(gradient_image_recreate, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0, 30, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is happening when this matrix multiplication is performed? To reiterate, each row of $H$ is responsible for \"illuminating,\" or selecting, a single pixel in the gradient image! `gradient_image_vector` was created by converting the 5x5 `gradient_image` into a 1D *column vector*. Similarly, *every row* in $H$ can be represented as a 5x5 image that, in real imaging, would be projected over `gradient_image`. \n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Iterate through each row of the matrix $H$. *Reshape* each row into a 5x5 image, and check that each row illuminates a unique pixel of the original 5x5 image! Based on $ \\vec{s} = H \\vec{i} $, why are the rows of $H$ used for masking when $\\vec{i}$ is a column vector?</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through rows of matrix H and form individual masks\n",
    "plt.figure(figsize = (20, 20)) \n",
    "for k in range(25):\n",
    "    plt.subplot(5, 5, k + 1)\n",
    "    \n",
    "    mask = # YOUR CODE HERE\n",
    "    \n",
    "    plt.imshow(mask, cmap = \"gray\", interpolation = \"nearest\")\n",
    "    plt.title(\"Mask \" + str(k) + \" = Row \" + str(k) + \" of Matrix H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the images above are masks. During a single scan, we project one of these masks over our image. The white pixel illuminates a particular location on the image that we want to capture, and the black pixels obscure the other parts of the image. Thus, using the rows of $H$, we gather information one pixel at a time.\n",
    "\n",
    "Let's try to make a mask matrix that's a little more complicated. We want the first half of $\\vec{s}$ to contain information on every other pixel of the image (i.e. $iv_{00}$, $iv_{02}$, $iv_{20}$...). The second half of $\\vec{s}$ should consist of information on the pixels that the first half skipped (i.e. $iv_{01}$, $iv_{03}$, $iv_{10}$).\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Generate `H_Alt` whose first half (in terms of rows) illuminates every other pixel of $\\vec{i}$ and whose second half illuminates the pixels that were skipped. Multiply `H_Alt` by `gradient_image_vector` to produce the `s` described previously.\n",
    "</span>**\n",
    "\n",
    "*<b>Hint</b>: Try to use rows from the existing H matrix. The syntax to slice an np array is as follows `array[starting_row:stopping_row:skip,starting_col:stopping_col:skip]`. `np.vstack` may be very helpful (try Googling it). If done well, the code to generate H_Alt should only be 1 short line*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the new mask matrix `H_Alt`\n",
    "H_Alt = # YOUR CODE HERE\n",
    "\n",
    "# Display `H_Alt`\n",
    "plt.figure()\n",
    "plt.imshow(H_Alt, cmap = \"gray\", interpolation = \"nearest\")\n",
    "\n",
    "# TODO: Multiply `H_Alt` and `gradient_image_vector`\n",
    "s = # YOUR CODE HERE\n",
    "\n",
    "# Display the result `s` and compare to `gradient_image_vector`\n",
    "plt.figure()\n",
    "plt.imshow(s, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of how we designed `H_Alt`, `s` is clearly different from `gradient_image_vector`. Each pixel of `gradient_image_vector` is still illuminated only once by `H_Alt`, but the order in which the pixels are illuminated has changed. Therefore, we say that `s` is a \"scrambled\" version of `gradient_image_vector`. How would we go about performing a \"reconstruction\" step that transforms the column vector `s` back into `gradient_image_vector`? Recall that our original `H` was actually the **identity** matrix $I_n$. \n",
    " \n",
    "$$M \\vec{s} = M H_{Alt} \\vec{i} = I_n \\vec{i} = \\vec{i} $$\n",
    "\n",
    "**<span style=\"color:red\">What should M be to recover $\\vec{i}$?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">YOUR COMMENTS HERE</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Write code to reconstruct `gradient_image_vector` from `s`.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reconstruct `gradient_image_vector`\n",
    "gradient_image_vector_reconstruct = # YOUR CODE HERE\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(gradient_image_vector_reconstruct, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task3'></a>\n",
    "# <span style=\"color:blue\">Task 2: Imaging Simulated Pictures</span>\n",
    "\n",
    "Finally, we will use our two matrices to simulate imaging a more complex picture. Because our picture is fairly large, we want each individual mask to have dimensions 32x32 (i.e. height = 32, width = 32). Think about how big the mask matrix was for the 5x5 example. In the next cell, you'll use the same logic to find the dimensions for the mask matrix of a 32x32 image.\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Recreate both the $H$ and $H_{Alt}$ masks to match these new dimensions. </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recreate `H`\n",
    "H = # YOUR CODE HERE\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(H, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recreate `H_Alt`      \n",
    "H_Alt = # YOUR CODE HERE\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(H_Alt, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that the two matrices we made are invertible and the correct size. Run the code block below to invert the matrices and test dimensions - if any of the lines fail, it means the code used to generate either matrix resulted in a incorrect size or non-invertible, linearly dependent matrix, which is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(H, H_Alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mask matrices must be saved as files before they can be used to perform real imaging. The files are read by our imaging script, as seen below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Run the cell below to save `H` and `H_Alt`!</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"saved_data/H.npy\", H)\n",
    "np.save(\"saved_data/H_Alt.npy\", H_Alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a id ='setup'><span style = \"color: blue\">Task 2a: Software Setup</span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need an object to simulate taking a picture of. You can use an image of your choice for this lab (or stick with the one we've provided :). We suggest using one that has a single object with a simple, light background; say your favorite logo/emoji/animal. \n",
    "\n",
    "Simply download one (using Google Images for example) or click a picture and store it in an easily accessible place on your computer. We also suggest using .jpg or .jpeg file formats (feel free to convert .png files to these formats).\n",
    "\n",
    "This lab is designed to work with 32x32 images. We have provided a resizing script to make sure that your image works with the simulator. However, selecting a high-resolution / detailed image may lead to a possible unrecognizable resized image as 32x32px images have comparatively low resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the pane on the left, hit the upward facing arrow on top (`Upload` button).\n",
    "\n",
    "<br>\n",
    "<center><img src=\"images/upload_instructions.png\" align=\"center\"/ width=\"1279\" height=\"761\">   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<left>2. Navigate to your image in the pop-out window, select it and click on \"Open\".\n",
    "    \n",
    "<br>    \n",
    "<center><img src=\"images/upload_instructions_2.png\" align=\"center\"/ width=\"1218\" height=\"720\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<left>3. You should see the image added to the directory.\n",
    "    \n",
    "<br>    \n",
    "<center><img src=\"images/upload_instructions_3.png\" align=\"center\"/ width=\"1218\" height=\"720\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab is designed to work with 32x32 images. `imageResize()` takes your (higher quality) image, picks the center portion of it, and reduces its quality to fit the desired size.\n",
    "\n",
    "**<span style=\"color:red\">Set `uploadPath` to the name of the image you've chosen </span>** (with its extension, for example \"picture.jpg\") and **<span style=\"color:red\">set `imagePath` to the name you want the resized imaged to have </span>**(with its extension, for example \"picture.jpg\") . Make sure you set `imagePath` to the same name in future code blocks.\n",
    "\n",
    "**Note: Another reminder that passing in a path to a high-resolution / detailed image may lead to a badly resized image as 32x32px images have comparatively low resolution. The new image might be unrecognizable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (so you don't have to start from the top)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run scripts/helpers.py\n",
    "%matplotlib inline\n",
    "\n",
    "# Image Resize\n",
    "uploadPath = \"eecs16a.jpg\" #TODO: replace with your uploaded image file path\n",
    "imagePath = \"eecs16a32x32.jpg\" #TODO: replace with the filename for your resized image\n",
    "height = 32\n",
    "width = 32\n",
    "imageResize(uploadPath, imagePath, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">You will then run the `masking_simulation.py` script below that projects mask patterns onto your image based on the $H$ matrix that you designed. </span>**  This script controls the scanning process. The following cell runs `cumulative_imaging_simulation.py` which will display the sensor vector reshaped to the original image's dimensions.\n",
    "\n",
    "The commands in the code block below use the following tags: \n",
    "- `--mask`: points to the file (with its extension, for example \"matrix.npy\") associated with the mask matrix you want to use \n",
    "- `--width`, `--height`: dimensions of the image being scanned\n",
    "- `--image`: specifies the path to the image being scanned (with its extension, for example \"picture.jpg\")\n",
    "- `--overlay` (**`masking_simulation.py`** only): see each mask overlaid on the image. It is set to True by default. \n",
    "\n",
    "When running **`masking_simulation.py`**, a popup widget will appear, depicting the masks being applied to the image during each scan. The call to `simulateIdealImaging` directly below this will save the resulting sensor vector to the file specified by sensorFilename. \n",
    "\n",
    "When **`cumulative_imaging_simulation.py`** begins running, the centered popup widget will go through the captured brightness values collected so far as the number of scans increases.\n",
    "\n",
    "`masking_simulation.py` iterates over the rows of the $H$ matrix you made. These rows are translated, one-by-one, into real masks projected onto the screen. Sensor readings are taken for each mask. At the start of the scan, you'll see a series of `Count: # Brightness value: #` printed to the output below. `Count` corresponds to the index $k$ of the current sensor reading (and likewise current row of H). `Brightness` corresponds to the digitized value obtained from imaging using the given mask. This \"debug\" information is printed consecutively for the first few sensor outputs. Otherwise, this info is printed when `k % 100 = 0` (every 100 scans). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">1. Make sure you've set the variables at the beginning of each simulation code block, i.e., `imagePath`, `sensorFileName` and `H`/`H_Alt` correctly.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">2. Please click on this <a href=\"https://eecs.datahub.berkeley.edu/hub/user-redirect/desktop\">link</a> before proceeding any further. It will open another browser tab where the visuals will be visible. Login with your CalNet ID, if prompted. If you see a pop-up in the middle of your screen, click on `Use Default Config`. Then return back to this notebook tab.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: In a real-world projector setup (**not in this virtual arrangement**), scanning would take much longer (a few minutes) because:*\n",
    "* We average sensor readings to improve the signal-to-noise ratio. Therefore we need to read more times.\n",
    "* As you'll learn in Module 2, capacitors take some time to charge and discharge. A capacitor acts as a \"low-pass filter.\" We used a 0.1$\\mu$F capacitor in our sensing circuit to \"smooth\" the output and suppress \"high-frequency\" noise. In order to give the capacitor time to \"settle\" (i.e. ~fully charge/discharge), we need to wait longer between scans. Otherwise, the sensor reading will also include some \"memory\" of the previous scan result, when we really want the reading to only be about the current scan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ideal Imaging\n",
    "H = np.load(\"saved_data/H.npy\")\n",
    "imagePath = #TODO: your image path here\n",
    "sensorFilename = \"saved_data/s_vec\"\n",
    "\n",
    "#As soon as you run this block, please open the browser tab with the visuals. \n",
    "#Once both visuals have finished executing, please return to this notebook tab.\n",
    "\n",
    "%run scripts/masking_simulation.py --width 32 --height 32 --mask \"saved_data/H.npy\" --image $imagePath --sleepTime 10\n",
    "simulateIdealImaging(imagePath, H, sensorFilename, height, width)\n",
    "\n",
    "%run scripts/cumulative_imaging_simulation.py --width 32 --height 32 --mask \"saved_data/H.npy\" --image $imagePath --sleepTime 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the sensor readings have been captured, load the sensor reading vector into the cell below. Once again, here is the equation relating $H$, the sensor reading column vector $\\vec{s}$, and the image column vector $\\vec{i}$:\n",
    "\n",
    "$$\\vec{s} = H \\vec{i}$$\n",
    "\n",
    "**<span style=\"color:red\">Recreate the image from the sensor readings obtained with `H`.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor readings\n",
    "sr = np.load(sensorFilename + \".npy\")\n",
    "\n",
    "# TODO: Create the image vector from `H` and `sr`\n",
    "# Hint: Because `H` is a special matrix, technically you do not need to perform any matrix operations\n",
    "iv = # YOUR CODE HERE\n",
    "\n",
    "img = np.reshape(iv, (height, width))\n",
    "plt.imshow(img, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate the noisy behavior of a real-world projector setup, run the following cell. We'll be coming back to the effect of noise on captured and reconstructed images in the next lab so don't worry too much about how this works right now. Feel free to play around with the `sigma` parameter to observe its effect on noisiness of the reconstructed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Noisy Imaging\n",
    "sigma = 30 # you can play around with this noise parameter\n",
    "H = np.load(\"saved_data/H.npy\")\n",
    "sensorFilename = \"saved_data/s_vec_nonideal\"\n",
    "\n",
    "#As soon as you run this block, please open the browser tab with the visuals. \n",
    "#Once both visuals have finished executing, please return to this notebook tab.\n",
    "\n",
    "%run scripts/masking_simulation.py --width 32 --height 32 --mask \"saved_data/H.npy\" --image $imagePath --sleepTime 10\n",
    "simulateRealImaging(imagePath, H, sensorFilename, height, width, sigma)\n",
    "\n",
    "# remember to change the --noise tag here too!\n",
    "%run scripts/cumulative_imaging_simulation.py --width 32 --height 32 --mask \"saved_data/H.npy\" --image $imagePath --sleepTime 10 --noise $sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor readings\n",
    "sr = np.load(sensorFilename + \".npy\")\n",
    "\n",
    "# TODO: Create the image vector from `H` and `sr`\n",
    "# Hint: Because `H` is a special matrix, technically you do not need to perform any matrix operations\n",
    "iv = # YOUR CODE HERE\n",
    "\n",
    "img = np.reshape(iv, (height, width))\n",
    "plt.imshow(img, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have simulated imaging your first image using your virtual single pixel camera! \n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Does your recreated image match the real image? What are some problems you notice? \n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">`YOUR COMMENTS HERE`</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here is an example picture we took using the real-world lab setup:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/ee16a_picture.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Next, use the second mask `H_Alt` for imaging. Can you repeat the same reconstruction procedure just by replacing $H$ with $H_{Alt}$? Why or why not?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR COMMENTS HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the scripts again (taking the same precautions as above) to collect sensor readings. Make sure to run it from the code block below to point the script to `H_Alt`. Then reconstruct the image.\n",
    "\n",
    "Don't forget to set the imagePath variable again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideal Imaging\n",
    "H_Alt = np.load(\"saved_data/H_Alt.npy\")\n",
    "imagePath = #TODO: your image path here\n",
    "sensorFilename = \"saved_data/s_alt_vec\"\n",
    "\n",
    "#As soon as you run this block, please open the browser tab with the visuals. \n",
    "#Once both visuals have finished executing, please return to this notebook tab.\n",
    "\n",
    "%run scripts/masking_simulation.py --width 32 --height 32 --mask \"saved_data/H_Alt.npy\" --image $imagePath --sleepTime 10\n",
    "simulateIdealImaging(imagePath, H_Alt, sensorFilename, height, width)\n",
    "\n",
    "%run scripts/cumulative_imaging_simulation.py --width 32 --height 32 --mask \"saved_data/H_Alt.npy\" --image $imagePath --sleepTime 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor readings\n",
    "sr = np.load(sensorFilename + \".npy\")\n",
    "\n",
    "plt.imshow(np.reshape(sr, (width, height)), cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.title('Sensor Reading, Using H_Alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the image vector from `H_Alt` and `sr`\n",
    "# Hint: You need to perform a matrix operation before multiplying\n",
    "iv =  # YOUR CODE HERE\n",
    "\n",
    "img = np.reshape(iv, (height, width))\n",
    "\n",
    "plt.imshow(img, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate the noise a real projector setup can introduce again, this time for the $H_{Alt}$ mask matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Noisy Imaging\n",
    "sigma = 30 # you can play around with this noise parameter\n",
    "H_Alt = np.load(\"saved_data/H_Alt.npy\")\n",
    "sensorFilename = \"saved_data/s_alt_vec_nonideal\"\n",
    "\n",
    "#As soon as you run this block, please open the browser tab with the visuals. \n",
    "#Once both visuals have finished executing, please return to this notebook tab.\n",
    "\n",
    "%run scripts/masking_simulation.py --width 32 --height 32 --mask \"saved_data/H_Alt.npy\" --image $imagePath --sleepTime 10\n",
    "simulateRealImaging(imagePath, H_Alt, sensorFilename, height, width, sigma)\n",
    "\n",
    "# remember to change the --noise tag here too!\n",
    "%run scripts/cumulative_imaging_simulation.py --width 32 --height 32 --mask \"saved_data/H_Alt.npy\" --image $imagePath --sleepTime 10 --noise $sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor readings\n",
    "sr = np.load(sensorFilename + \".npy\")\n",
    "\n",
    "plt.imshow(np.reshape(sr, (width, height)), cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.title('Sensor Reading, Using H_Alt with Noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the image vector from `H_Alt` and `sr`\n",
    "# Hint: You need to perform a matrix operation before multiplying\n",
    "iv = # YOUR CODE HERE\n",
    "\n",
    "img = np.reshape(iv, (height, width))\n",
    "\n",
    "plt.imshow(img, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You are done for the week, and are ready to sign up for checkoff. DO NOT delete / close your notebook before being checked off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='checkoff'></a>\n",
    "## Checkoff\n",
    "When you are ready to get checked off,\n",
    "1. Fill out the checkoff google form. **[Checkoff Form](https://forms.gle/TLjsE68kEf8QpcWa9)**\n",
    "2. Submit a **checkoff** request on the lab queue. **[Checkoff queue](https://lab.eecs16a.org)** It is fine if only one person from your group submits the lab queue request, but everyone must submit their own google form. \n",
    "\n",
    "Your GSI or a Lab Assistant will join your breakout room when they are available and go through some checkoff questions with your group. They will go through the checkoff list in order. Please be patient!\n",
    "\n",
    "## **<span style=\"color:red\"> Please have your notebook ready to demo before being checked off. </span>**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
